{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUTURES \n",
    "\n",
    "A future, or promise, is something that represents a pending opearion and returns straight away. One can then query their state of completion, or register callbacks to be called on successful completion or error.\n",
    "\n",
    "Adapted from Fluent Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "yield was this concept of ...\n",
    "\n",
    "Concept of futures: If you have a computation or process that will take a long time. Instead of blocking or waiting for it to complete, return the token to you right now even if process is not done yet. Ask for tokens to indicate whether complete or not. Or register a callback and when done, call a function that maybe puts stuff into database or changes global variable to change whatever. \n",
    "\n",
    "Context of coroutine or thread having finished its work. Notion of having completed the work. \n",
    "\n",
    "There's a module called concurrent. \n",
    "\n",
    "Way to doing concurrent processes and threads. \n",
    "\n",
    "Multiple processes going on, etc. Or multiple websites. There's some unit of I/O or computation. \n",
    "\n",
    "So let's start with threads. We have a vague notion of thread - some notion of level of process, but can have multiple threads. \n",
    "\n",
    "If you do time.sleep, will give up lock and lets other threads happen. Good thing to play around\n",
    "\n",
    "This is what happens when go to website? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES - K\n",
    "\n",
    "Future - a value that will be available at some point in the future\n",
    "\n",
    "Don't conflate with the Python implementation of Future \n",
    "\n",
    "Often use future to represent the result of an asyncronous process.\n",
    "\n",
    "Sort of explicit form of lazy evaluations\n",
    "\n",
    "Allows you to do other useful work  before you block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid, time\n",
    "def get_thing(it):\n",
    "    sleep(1)\n",
    "    return uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examples from Fluent Python \n",
    "# get updated code from Rahul\n",
    "\n",
    "import time, uuid, functools\n",
    "def get_thing_maker(secs, items):\n",
    "    time.sleep(secs)\n",
    "    return str(uuid.uuid4())+str(items)\n",
    "get_thing = functools.partial(get_thing_maker, 1)\n",
    "def get_many(lots):\n",
    "    counter = 0\n",
    "    for t in lots: \n",
    "        thing = get_thing(t)\n",
    "        counter += 1\n",
    "    return counter\n",
    "\n",
    "def serial_main(it):\n",
    "    t0 = time.time()\n",
    "    count = get_many(it)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} things got in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serial sleeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 things got in 20.08s\n"
     ]
    }
   ],
   "source": [
    "serial_main(range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concurrent sleeping using threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "creates 10 threads for us usin this and stored in executor \n",
    "\n",
    "10 threats, 20 functions to run. It will take care of all the details of spawning and joining threads. \n",
    "\n",
    "Some of these functions \n",
    "\n",
    "By doing these threads, because when running thread, any other thread cannot run. But all this thread is doing is sleeping. As I/O goes on, and then tell threads to go, and then pass along locks. \n",
    "\n",
    "That's the game that's happening over here. \n",
    "\n",
    "May think that global interpter lock (GIL) is a problem, but it's not. For most part of doing I/O type stuff, it's not a problem at all. Can always get away with doing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "def get_many_threaded1(it):\n",
    "    workers = 10\n",
    "    with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        # TODO This is a cool pattern, parallelism, can map pretty much anthing that blocks\n",
    "        # this will nicel parallezlie and schedule for ou\n",
    "        \n",
    "        res = executor.map(get_thing, it)\n",
    "    return len(list(res))\n",
    "def threaded_main1(it):\n",
    "    t0 = time.time()\n",
    "    count = get_many_threaded1(it)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} things got in {:.2f}s' \n",
    "    print(msg.format(count, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 things got in 2.01s\n"
     ]
    }
   ],
   "source": [
    "threaded_main1(range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might think that the concurrent IO (or sleeping) case is limited by the GIL, but in both cases, the GIL is yielded. Thus there is no waiting around.\n",
    "\n",
    "The GIL is harmless if code is being run in the context of python library IO or code running in properly coded C extensions like numpy.  The time.sleep() function also releases the GIL. Python threads are totally usable in I/O-bound applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES - Threads vs. Processes\n",
    "\n",
    "This is how all processes work in all unix machines work. It just keeps forking to create more processes and memory space keeps duplicating. \n",
    "\n",
    "parent waits on child, then child finishes, then exits status. \n",
    "\n",
    "What's the characteristic of process? Stack, registers allocated, memory allocation. \n",
    "\n",
    "A process is a container. Every process has at least one thread. Could ahve mlutiple threads. What does this mean? Could have multiple units of execution and to have multiple units of execution, each one has its own stack to have its own call stack and possibly to ahve regisers. Needs to have a program counter to tell you where you are in. These are things that are properties of processes. All share the same memory address as all the threads. So this thread idea can think of idea of decoupling of this notion of what is a process here and what the resources that a process has. \n",
    "\n",
    "These are the things that a process has: address space, global variables, etc. \n",
    "\n",
    "Thread level: registers. \n",
    "\n",
    "Can have user vs. kernel threads .... kernrel threads are actually managed by OS for you. Don't have to worry about these things. Generally, as a writer of a program, have a user space library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads\n",
    "\n",
    "threads vs processes\n",
    "\n",
    "On linux\n",
    "\n",
    "- processes created by fork()\n",
    "- have a primary thread\n",
    "- thread is the unit of execution\n",
    "- process is a container, can have more threads\n",
    "- can be scheduled across different cores/cpus\n",
    "\n",
    "```c\n",
    "int pid;\n",
    "int status = 0;\n",
    "/* fork returns pid of child to parent and 0 to child*/\n",
    "if (pid = fork()) {\n",
    "    /* parent code */\n",
    "    pid = wait(&status);\n",
    "    /*wait returns child pid and status*/\n",
    "} else {\n",
    "    /* child  code*/\n",
    "    exit(status);\n",
    "} \n",
    "```\n",
    "\n",
    "- threads in a process share same address space (share it entirely)\n",
    "- thread abstraction decouples resource allocation from control\n",
    "- defines a single sequential execution stream with PC, stack, register values\n",
    "- process handles: address space, global variables, open files, child processes, pending alarms, signals and signal handlers, accounting info\n",
    "- thread handles program counter, registers, stack, and state\n",
    "- user vs kernel threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here's our old fib as one liner. This is worst way...exponential complexity. Expemplar of CPU bound process.\n",
    "# Burgeoninng large stack. Not using any other memory\n",
    "def fib(n):\n",
    "    return fib(n - 1) + fib(n - 2) if n > 1 else n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(0) is 0\n",
      "fib(1) is 1\n",
      "fib(2) is 1\n",
      "fib(3) is 2\n",
      "fib(4) is 3\n",
      "fib(5) is 5\n",
      "fib(6) is 8\n",
      "fib(7) is 13\n",
      "fib(8) is 21\n",
      "fib(9) is 34\n",
      "fib(10) is 55\n",
      "fib(11) is 89\n",
      "fib(12) is 144\n",
      "fib(13) is 233\n",
      "fib(14) is 377\n",
      "fib(15) is 610\n",
      "fib(16) is 987\n",
      "fib(17) is 1597\n",
      "fib(18) is 2584\n",
      "fib(19) is 4181\n",
      "fib(20) is 6765\n",
      "fib(21) is 10946\n",
      "fib(22) is 17711\n",
      "fib(23) is 28657\n",
      "fib(24) is 46368\n",
      "fib(25) is 75025\n",
      "fib(26) is 121393\n",
      "fib(27) is 196418\n",
      "fib(28) is 317811\n",
      "fib(29) is 514229\n",
      "fib(30) is 832040\n",
      "fib(31) is 1346269\n",
      "fib(32) is 2178309\n",
      "fib(33) is 3524578\n",
      "fib(34) is 5702887\n",
      "cpuy2 fib(0) is 0\n",
      "cpuy2 fib(1) is 1\n",
      "cpuy2 fib(2) is 1\n",
      "cpuy2 fib(3) is 2\n",
      "cpuy2 fib(4) is 3\n",
      "cpuy2 fib(5) is 5\n",
      "cpuy2 fib(6) is 8\n",
      "cpuy2 fib(7) is 13\n",
      "cpuy2 fib(8) is 21\n",
      "cpuy2 fib(9) is 34\n",
      "cpuy2 fib(10) is 55\n",
      "cpuy2 fib(11) is 89\n",
      "cpuy2 fib(12) is 144\n",
      "cpuy2 fib(13) is 233\n",
      "cpuy2 fib(14) is 377\n",
      "cpuy2 fib(15) is 610\n",
      "cpuy2 fib(16) is 987\n",
      "cpuy2 fib(17) is 1597\n",
      "cpuy2 fib(18) is 2584\n",
      "cpuy2 fib(19) is 4181\n",
      "cpuy2 fib(20) is 6765\n",
      "cpuy2 fib(21) is 10946\n",
      "cpuy2 fib(22) is 17711\n",
      "cpuy2 fib(23) is 28657\n",
      "cpuy2 fib(24) is 46368\n",
      "cpuy2 fib(25) is 75025\n",
      "cpuy2 fib(26) is 121393\n",
      "cpuy2 fib(27) is 196418\n",
      "cpuy2 fib(28) is 317811\n",
      "cpuy2 fib(29) is 514229\n",
      "cpuy2 fib(30) is 832040\n",
      "cpuy2 fib(31) is 1346269\n",
      "cpuy2 fib(32) is 2178309\n",
      "cpuy2 fib(33) is 3524578\n",
      "cpuy2 fib(34) is 5702887\n",
      "serial elapsed: 15.904904127120972\n",
      "cpuy2 fib(0) is 0\n",
      "cpuy2 fib(1) is 1\n",
      "cpuy2 fib(2) is 1\n",
      "cpuy2 fib(3) is 2\n",
      "cpuy2 fib(4) is 3\n",
      "cpuy2 fib(5) is 5\n",
      "cpuy2 fib(6) is 8\n",
      "cpuy2 fib(7) is 13\n",
      "cpuy2 fib(8) is 21\n",
      "cpuy2 fib(9) is 34\n",
      "cpuy2 fib(10) is 55\n",
      "cpuy2 fib(11) is 89\n",
      "cpuy2 fib(12) is 144\n",
      "cpuy2 fib(13) is 233\n",
      "cpuy2 fib(14) is 377\n",
      "cpuy2 fib(15) is 610\n",
      "cpuy2 fib(16) is 987\n",
      "cpuy2 fib(17) is 1597\n",
      "cpuy2 fib(18) is 2584\n",
      "cpuy2 fib(19) is 4181\n",
      "fib(0) is 0\n",
      "fib(1) is 1\n",
      "fib(2) is 1\n",
      "fib(3) is 2\n",
      "fib(4) is 3\n",
      "fib(5) is 5\n",
      "fib(6) is 8\n",
      "fib(7) is 13\n",
      "fib(8) is 21\n",
      "fib(9) is 34\n",
      "fib(10) is 55\n",
      "fib(11) is 89\n",
      "fib(12) is 144\n",
      "fib(13) is 233\n",
      "fib(14) is 377\n",
      "fib(15) is 610\n",
      "fib(16) is 987\n",
      "fib(17) is 1597\n",
      "fib(18) is 2584\n",
      "fib(19) is 4181\n",
      "cpuy2 fib(20) is 6765\n",
      "fib(20) is 6765\n",
      "cpuy2 fib(21) is 10946\n",
      "fib(21) is 10946\n",
      "fib(22) is 17711\n",
      "cpuy2 fib(22) is 17711\n",
      "cpuy2 fib(23) is 28657\n",
      "fib(23) is 28657cpuy2 fib(24) is 46368\n",
      "\n",
      "fib(24) is 46368\n",
      "cpuy2 fib(25) is 75025\n",
      "fib(25) is 75025\n",
      "cpuy2 fib(26) is 121393\n",
      "fib(26) is 121393\n",
      "cpuy2 fib(27) is 196418\n",
      "fib(27) is 196418\n",
      "cpuy2 fib(28) is 317811\n",
      "fib(28) is 317811\n",
      "cpuy2 fib(29) is 514229\n",
      "fib(29) is 514229\n",
      "cpuy2 fib(30) is 832040\n",
      "fib(30) is 832040\n",
      "cpuy2 fib(31) is 1346269\n",
      "fib(31) is 1346269\n",
      "cpuy2 fib(32) is 2178309\n",
      "fib(32) is 2178309\n",
      "cpuy2 fib(33) is 3524578\n",
      "fib(33) is 3524578\n",
      "cpuy2 fib(34) is 5702887\n",
      "fib(34) is 5702887\n",
      "thread elapsed: 17.80691385269165\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "from time import time\n",
    "\n",
    "\n",
    "# sleeps for 3 seconds. Goes in a loop. Loop runs 10 times, sleeps 3 seconds each time. \n",
    "# Print statement with flush = True because it flushes the standard out first. Want to do that because there's \n",
    "# a cell to run but not much to do, but wondering why the other cell hasn't gone yet... has * because trying to \n",
    "# send to stdout but waiting for other process to do. Flush will force out stdout\n",
    "# stdout, don't want to be waiting to write stuff out all the time. \n",
    "\n",
    "# IO bound: spending most of program getting stuff from disk or network, not computationally heavy. \n",
    "# CPU bound (compute-bound): fibonacci - long running computational process and long chain of stuff\n",
    "# if have program that is IO bound, just use threads (for asyncronous, less bug prone) or coroutines (for thread-based), \n",
    "# will not be a problem\n",
    "# In python, shoudl not use threads to write compute-bound program, separate threads.. will hold onto GIL and not let \n",
    "# other threads go\n",
    "def sleepy(): #like io\n",
    "    i=0\n",
    "    while i < 10:\n",
    "        print(\"{} -- {} Sleepy!\".format(i, int(time())), flush=True)\n",
    "        sleep(3)\n",
    "        i += 1\n",
    "\n",
    "# cpuy and cpuy2 are identical, just wanted to separate out\n",
    "def cpuy():\n",
    "    for i in range(35):\n",
    "        val = fib(i)\n",
    "        print(\"fib({}) is {}\".format(i, val))\n",
    "\n",
    "def cpuy2():\n",
    "    for i in range(35):\n",
    "        val = fib(i)\n",
    "        print(\"cpuy2 fib({}) is {}\".format(i, val))\n",
    "        \n",
    "\n",
    "# let's see how much time it takes to run cpuy 2 threads one after the other\n",
    "def main():\n",
    "    # Second thread will print the hello message. Starting as a daemon means\n",
    "    # the thread will not prevent the process from exiting.\n",
    "    \n",
    "    # run these calculations in serial\n",
    "    start = time()\n",
    "    cpuy()\n",
    "    cpuy2()\n",
    "    print(\"serial elapsed:\", time() - start)\n",
    "    \n",
    "    \n",
    "    # now try running as threads \n",
    "    # TODO understand what this is doing\n",
    "    start=time()\n",
    "    #t = Thread(target=sleepy)\n",
    "    #t.start()\n",
    "    # start a thread... simple to do \n",
    "    t2 = Thread(target=cpuy2)\n",
    "    t2.start()\n",
    "    # Main thread will read and process input\n",
    "    cpuy()\n",
    "    print(\"thread elapsed:\", time() - start)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "# NOTES\n",
    "# there was no advantage to running as 2 threads. Actaully took longer than running in serial\n",
    "# naively, thought this would take time to run in any one functions... like 10 seconds which is half of running in serial\n",
    "# the GIL is forcing the threads to run in serial, that's why it's taking 20 seconds \n",
    "# the way this works in CPU bound process, doesn't give up any GIL \n",
    "# in IO bound processes, it gives up the GIL \n",
    "# in Python, about every 100-200 instructions of byte code, it will give up GIL to see if anything else runs\n",
    "# there's only one runing at any time. So you can't really do anything\n",
    "\n",
    "# Sklearn - njobs, njobs tells you how many jobs you can run. Does not use threads. Uses multiprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processes with concurrent futures.\n",
    "\n",
    "CPU based processing wont release the gil, and is thus best done in a separate process. For illustration, we show what this looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "Sklearn - njobs, njobs tells you how many jobs you can run. Does not use threads. Uses multiprocessing \n",
    "Using multiple processes here shouldn't be useful. \n",
    "\n",
    "Multiple processes and sleeping 1 second\n",
    "\n",
    "Don't really need to do multiple processes. \n",
    "\n",
    "Because threads will give up the gil. Don't have to do multiple processes. Just doing this to show it's the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def get_many_process(it, workers=None):\n",
    "    if workers:\n",
    "        with futures.ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "            res = executor.map(get_thing, it)\n",
    "    else:\n",
    "        with futures.ProcessPoolExecutor() as executor:\n",
    "            res = executor.map(get_thing, it)\n",
    "    return len(list(res))\n",
    "\n",
    "def process_main(it, workers=None):\n",
    "    t0 = time.time()\n",
    "    count = get_many_process(it, workers)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} things got in {:.2f}s' \n",
    "    print(msg.format(count, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 things got in 3.05s\n"
     ]
    }
   ],
   "source": [
    "process_main(range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 things got in 2.05s\n"
     ]
    }
   ],
   "source": [
    "# for the same reasons. \n",
    "process_main(range(20), workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n"
     ]
    }
   ],
   "source": [
    "# this is just demosntrating name is __main__\n",
    "print(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(0) is 0\n",
      "fib(1) is 1\n",
      "fib(2) is 1\n",
      "fib(3) is 2\n",
      "fib(4) is 3\n",
      "fib(5) is 5\n",
      "fib(6) is 8\n",
      "fib(7) is 13\n",
      "fib(8) is 21\n",
      "fib(9) is 34\n",
      "fib(10) is 55\n",
      "fib(11) is 89\n",
      "fib(12) is 144\n",
      "fib(13) is 233\n",
      "fib(14) is 377\n",
      "fib(15) is 610\n",
      "fib(16) is 987\n",
      "fib(17) is 1597\n",
      "fib(18) is 2584\n",
      "fib(19) is 4181\n",
      "fib(20) is 6765\n",
      "fib(21) is 10946\n",
      "fib(22) is 17711\n",
      "fib(23) is 28657cpuy2 fib(0) is 0\n",
      "cpuy2 fib(1) is 1\n",
      "cpuy2 fib(2) is 1\n",
      "cpuy2 fib(3) is 2\n",
      "cpuy2 fib(4) is 3\n",
      "cpuy2 fib(5) is 5\n",
      "cpuy2 fib(6) is 8\n",
      "cpuy2 fib(7) is 13\n",
      "cpuy2 fib(8) is 21\n",
      "cpuy2 fib(9) is 34\n",
      "cpuy2 fib(10) is 55\n",
      "cpuy2 fib(11) is 89\n",
      "cpuy2 fib(12) is 144\n",
      "cpuy2 fib(13) is 233\n",
      "cpuy2 fib(14) is 377\n",
      "cpuy2 fib(15) is 610\n",
      "cpuy2 fib(16) is 987\n",
      "cpuy2 fib(17) is 1597\n",
      "cpuy2 fib(18) is 2584\n",
      "cpuy2 fib(19) is 4181\n",
      "cpuy2 fib(20) is 6765\n",
      "cpuy2 fib(21) is 10946\n",
      "cpuy2 fib(22) is 17711\n",
      "\n",
      "fib(24) is 46368\n",
      "fib(25) is 75025cpuy2 fib(23) is 28657\n",
      "cpuy2 fib(24) is 46368\n",
      "\n",
      "fib(26) is 121393cpuy2 fib(25) is 75025\n",
      "\n",
      "fib(27) is 196418cpuy2 fib(26) is 121393\n",
      "\n",
      "fib(28) is 317811cpuy2 fib(27) is 196418\n",
      "\n",
      "fib(29) is 514229cpuy2 fib(28) is 317811\n",
      "cpuy2 fib(29) is 514229\n",
      "\n",
      "fib(30) is 832040cpuy2 fib(30) is 832040\n",
      "\n",
      "fib(31) is 1346269cpuy2 fib(31) is 1346269\n",
      "\n",
      "fib(32) is 2178309cpuy2 fib(32) is 2178309\n",
      "\n",
      "fib(33) is 3524578cpuy2 fib(33) is 3524578\n",
      "\n",
      "fib(34) is 5702887cpuy2 fib(34) is 5702887\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0a7fdf3ccb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcpuy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mp elapsed:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# identical example with threads\n",
    "# instead of multi-threading \n",
    "# doing multi-processing \n",
    "\n",
    "# now it takes 14 seconds, not 10 seconds because of startup and overhead\n",
    "# in cpubound process, this woul otherwise tak 20 seconds, reduce to 14 seconds. \n",
    "\n",
    "# Takeaway \n",
    "# cpu bound - use multiprocessing, because it will be faster \n",
    "# io bound - use multithreading \n",
    "import multiprocessing\n",
    "start = time.time()\n",
    "p=multiprocessing.Process(target=cpuy2)\n",
    "p.start()\n",
    "cpuy()\n",
    "p.join()\n",
    "print(\"mp elapsed:\", time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES Takeaway \n",
    "cpu bound - use multiprocessing, because it will be faster \n",
    "\n",
    "io bound - use multithreading \n",
    "\n",
    "If I wanted to write a process that kept doing some long standing computation, what's the simplest code? \n",
    "\n",
    "While 1: \n",
    "    ... \n",
    "   \n",
    "That front end process, which is basically this repl loop, you could run in main process \n",
    "\n",
    "Background computation could do... \n",
    "\n",
    "Problem with this is that ... \n",
    "\n",
    "What happens when you wait for input? Can't go forward and do any computations. That * means your' elocked until you do anything. What's going to happen is going to have these callbacks, but your main thread is blocked. Nothing can be done with this. Need to find a way to unlocking this, by using threads to give up GILs or something, or do something asyncronous. It's not enough just to have it run in process in back. This is a process you'll be implementing in your careers. It requires two things: 1) multi-threaded front end with process in back or requires 2) coroutine front end with process in back end. Doesn't have to be coroutine just anything that can be asyncronous. \n",
    "\n",
    "Otherwise callback would get stuck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input('>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES sockets\n",
    "\n",
    "very simple notion, there's a notion of opening a pipe to get data from that. \n",
    "\n",
    "For sockets, distinction between client and server\n",
    "\n",
    "client socket -- browser opens to get data from elsewhere. Loop exists which allowed to exist beacuse of server socket. Server socket waits for requests from client sockets. \n",
    "\n",
    "Again do that using threads or fork to handle threads to handle client socket on server side. Or can do asyncronous. 3 different ways to do it. Apache used to do it in old asycronous fashion. Apache added in way to do with threads. Node.js is completely asycnronous in one process. \n",
    "\n",
    "There's a disticntion between client and server socket. A stream and internet domain socket. \n",
    "\n",
    "Can have non blocking sockets using select system call. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sockets\n",
    "\n",
    "- distinction between \"client socket\" and \"server socket\"\n",
    "- default `socket.socket(family=AF_INET, type=SOCK_STREAM, proto=0, fileno=None)`\n",
    "- server socket sits and creates client sockets\n",
    "- non-blocking sockets and the `select` system call\n",
    "\n",
    "Read: https://docs.python.org/3.5/howto/sockets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a web page fetcher\n",
    "\n",
    "We'll eventually use the asyncio module to play with web page fetching and crawling, but lets build up to that by writing a simple fetcher. We'll start with blocking, then move to non-blocking, and finally to co-routines, and even more finally to `yield from` based co-routines.\n",
    "\n",
    "Adapted from http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blocking fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "def fetch(host, url):\n",
    "    sock = socket.socket()\n",
    "    sock.connect((host, 80))\n",
    "    request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(url, host)\n",
    "    sock.send(request.encode('ascii'))\n",
    "    response = b''\n",
    "    chunk = sock.recv(4096)\n",
    "    # if chunk comes back empty, then nothing else wmore to do\n",
    "    while chunk:\n",
    "        response += chunk\n",
    "        chunk = sock.recv(4096)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "b'HTTP/1.0 200 OK\\r\\nCache-Control: max-age=604800\\r\\nContent-Type: text/html\\r\\nDate: Sat, 02 Apr 2016 05:38:23 GMT\\r\\nEtag: \"359670651+gzip+ident\"\\r\\nExpires: Sat, 09 Apr 2016 05:38:23 GMT\\r\\nLast-Modified: Fri, 09 Aug 2013 23:54:35 GMT\\r\\nServer: ECS (bos/F56E)\\r\\nVary: Accept-Encoding\\r\\nX-Cache: HIT\\r\\nx-ec-custom-error: 1\\r\\nContent-Length: 1270\\r\\nConnection: close\\r\\n\\r\\n<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 50px;\\n        background-color: #fff;\\n        border-radius: 1em;\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        body {\\n            background-color: #fff;\\n        }\\n        div {\\n            width: auto;\\n            margin: 0 auto;\\n            border-radius: 0;\\n            padding: 1em;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.</p>\\n    <p><a href=\"http://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n'"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, IFrame\n",
    "HTML(str(fetch(\"www.example.com\",\"/\")))\n",
    "# converting a bunch of bytes to string, the passing it through Ipython HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO stopped paying attention here until rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic non-blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent\n"
     ]
    }
   ],
   "source": [
    "# underlying operating system, they look at a bunch of file descriptors, actual files have file descriptors \n",
    "# basically do I have any data on this? \n",
    "# \n",
    "host=\"www.example.com\"\n",
    "url=\"/\"\n",
    "request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(url, host)\n",
    "encoded = request.encode('ascii')\n",
    "sock = socket.socket()\n",
    "sock.setblocking(False)\n",
    "try:\n",
    "    sock.connect(('xkcd.com', 80))\n",
    "except BlockingIOError:\n",
    "    pass\n",
    "while True:\n",
    "    try:\n",
    "        sock.send(encoded)\n",
    "        break  # Done.\n",
    "    except OSError as e:\n",
    "        pass\n",
    "\n",
    "print('sent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has only been implemented partially. Notice how the `sock.send` spins in a loop.\n",
    "\n",
    "This eats cycles. the solution is to use select/kqueue/epoll from a small number of connections to a large number of them. The basic idea behind `select` is to wait for an event to occur on a small set of non-blocking sokets.\n",
    "\n",
    "We'll use python's `DefaultSelector`, an addition from python 3.4 that automatically chooses the \"best\" select like implementation on your system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectorKey(fileobj=56, fd=56, events=2, data=<function connected at 0x1072c3620>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selectors import DefaultSelector, EVENT_WRITE\n",
    "\n",
    "# set up selector here \n",
    "selector = DefaultSelector()\n",
    "host=\"www.example.com\"\n",
    "sock = socket.socket()\n",
    "sock.setblocking(False)\n",
    "try:\n",
    "    sock.connect((host, 80))\n",
    "except BlockingIOError:\n",
    "    pass\n",
    "\n",
    "# \n",
    "def connected():\n",
    "    selector.unregister(sock.fileno())\n",
    "    print('connected!', flush=True)\n",
    "\n",
    "# connected can be a function, class, or None or anything\n",
    "# finding some way to communicate to select loop that if had an event that something was written, then give connected, \n",
    "# basically prints 'connected'\n",
    "selector.register(sock.fileno(), EVENT_WRITE, connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`connected` is the **callback** run when the connection happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def loop():\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        if time.time() - start > 10:\n",
    "            break\n",
    "        events = selector.select()\n",
    "        # if any events, then this for loop will happen. Mask is not useful now. Key is main important thing. \n",
    "        # this is called an event loop where just sit and wait for something to happen\n",
    "        # 100 sockets and websites, then call some function \n",
    "        # now there's this notion of callbacks\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a loop is called an \"event loop\". An async frameworkhas two parts: (a) such an event loop and (b) non-blocking sockets. It all runs on one thread. This is a system, it should be obvious for I/O bound problems.\n",
    "\n",
    "What have we demonstrated already? We showed how to begin an operation and execute a callback when the operation is ready. An async framework builds on the two features we have shown—non-blocking sockets and the event loop—to run concurrent operations on a single thread.\n",
    "\n",
    "Guido:\n",
    ">We have achieved \"concurrency\" here, but not what is traditionally called \"parallelism\". What asynchronous I/O is right for, is applications with many slow or sleepy connections with infrequent events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected!\n"
     ]
    }
   ],
   "source": [
    "loop() #loop will destruct after 10 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### async with response reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "\n",
    "selector = DefaultSelector()\n",
    "class Fetcher:\n",
    "    def __init__(self, url, host):\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "        self.host = host\n",
    "        self.url = url\n",
    "        self.sock = None\n",
    "        \n",
    "    # Method on Fetcher class.\n",
    "    def fetch(self):\n",
    "        self.sock = socket.socket()\n",
    "        self.sock.setblocking(False)\n",
    "        try:\n",
    "            self.sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        # Register next callback.\n",
    "        selector.register(self.sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          self.connected)\n",
    "\n",
    "    def connected(self, key, mask):\n",
    "        print('connected!', flush=True)\n",
    "        selector.unregister(key.fd)\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(self.url, self.host)\n",
    "        self.sock.send(request.encode('ascii'))\n",
    "\n",
    "        # Register the next callback.\n",
    "        selector.register(key.fd,\n",
    "                          EVENT_READ,\n",
    "                          self.read_response)\n",
    "        \n",
    "    def read_response(self, key, mask):\n",
    "        global stopped\n",
    "        \n",
    "        chunk = self.sock.recv(128)  # USUALLY 4k chunk size, here small\n",
    "        if chunk:\n",
    "            print(\"read chunk\", flush=True)\n",
    "            self.response += chunk\n",
    "        else:\n",
    "            print(\"all read\", flush=True)\n",
    "            selector.unregister(key.fd)  # Done reading.\n",
    "            stopped=True\n",
    "            \n",
    "stopped = False\n",
    "\n",
    "def loop():\n",
    "    while not stopped:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback(event_key, event_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'socket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b1449b429fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfetcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/353/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xkcd.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ba92197d8efb>\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Method on Fetcher class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'socket' is not defined"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('/353/', 'xkcd.com')\n",
    "fetcher.fetch()\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the control-flow is chained together by having the connected callback do the resposing. Beyond a 2-3 ladder, this gets confusing and onerous (see some node.js code). As compared to a blocking program, where the continuation of the program is stored and adressed via the instruction pointer in a sequential fashiom, here the cintinuation is stored by registering the callbacks.'\n",
    "\n",
    "Since the current frame is popped out of the stack, exceptions have a hard time figuring the origin This is called stack-ripping.\n",
    "\n",
    "So, even apart from the long debate about the relative efficiencies of multithreading and async, there is this other debate regarding which is more error-prone: threads are susceptible to data races if you make a mistake synchronizing them, but callbacks are stubborn to debug due to stack ripping. And within a bit, we get callback soup.\n",
    "\n",
    "https://thesynchronousblog.wordpress.com/tag/stack-ripping/\n",
    "\n",
    "Threads seem to offer a more natural way of programming as the programmer with all state in thread’s single stack.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why not use them. As we said last time: synchronization and overhead. \n",
    "\n",
    "But we can do better with Coroutines!\n",
    "\n",
    "Guido:\n",
    ">We entice you with a promise. It is possible to write asynchronous code that combines the efficiency of callbacks with the classic good looks of multithreaded programming. This combination is achieved with a pattern called \"coroutines\". Using Python 3.4's standard asyncio library, and a package called \"aiohttp\", fetching a URL in a coroutine is very direct7:\n",
    "\n",
    "    @asyncio.coroutine\n",
    "    def fetch(self, url):\n",
    "        response = yield from self.session.get(url)\n",
    "        body = yield from response.read()\n",
    "        \n",
    "In 3.5 its even more clear:\n",
    "\n",
    "async def fetch(self, url):\n",
    "        response = await self.session.get(url)\n",
    "        body = await response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the Future with co-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "import socket\n",
    "selector = DefaultSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The future, as you might expect is something with callbacks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFuture:\n",
    "    def __init__(self):\n",
    "        self.result = None\n",
    "        self._callbacks = []\n",
    "\n",
    "    def add_done_callback(self, fn):\n",
    "        self._callbacks.append(fn)\n",
    "\n",
    "    def set_result(self, result):\n",
    "        self.result = result\n",
    "        for fn in self._callbacks:\n",
    "            fn(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a \"main\" to yield to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    \n",
    "    def __init__(self, url, host):\n",
    "        self.url = url\n",
    "        self.host = host\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "\n",
    "        \n",
    "    def fetch(self):\n",
    "        global stopped\n",
    "        sock = socket.socket()\n",
    "\n",
    "        sock.setblocking(False)\n",
    "        try:\n",
    "            sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        f = MyFuture()\n",
    "\n",
    "        #resolves the future by setting a result on it\n",
    "        def on_connected():\n",
    "            print('on connected cb ran', flush=True)\n",
    "            f.set_result(None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        selector.register(sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          on_connected)\n",
    "        print(\"about to yield connection future\", flush=True)\n",
    "        yield f#this makes it look like fetch has returned the \"future\"\n",
    "        #bit we have not lost the state (or have to have carried it in obj)\n",
    "        #a send in will continue us here\n",
    "        print('we were connected! now back in gen', flush=True)\n",
    "        selector.unregister(sock.fileno())\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(self.url, self.host)\n",
    "        sock.send(request.encode('ascii'))\n",
    "        while True:\n",
    "            print(\"in loop\")\n",
    "            #now create a new future for the data-recieving call\n",
    "            f = MyFuture()\n",
    "            def on_response():\n",
    "                chunky = sock.recv(4096)  # 4k chunk size.\n",
    "                f.set_result(chunky)\n",
    "            selector.register(sock.fileno(),\n",
    "                              EVENT_READ,\n",
    "                              on_response)\n",
    "            #now to restart the gen, we will from the main\n",
    "            #throw the data right back in\n",
    "            chunk = yield f\n",
    "            selector.unregister(sock.fileno())\n",
    "            if chunk:\n",
    "                print(\"len(chunk)\",len(chunk))\n",
    "                self.response += chunk\n",
    "            else:\n",
    "                print(\"all read\")\n",
    "                stopped= True\n",
    "                break\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#But when the future resolves, what resumes the generator? We need a coroutine driver. Let us call it \"task\":\n",
    "#(this is our main)\n",
    "class Task:\n",
    "    def __init__(self, coro):\n",
    "        self.coro = coro\n",
    "        f = MyFuture()\n",
    "        print(\">>sending none to initial future\",f)\n",
    "        f.set_result(None)\n",
    "        print(\"...stepping\")\n",
    "        self.step(f)\n",
    "        print(\">>>after priming\")\n",
    "\n",
    "    def step(self, future):\n",
    "        try:\n",
    "            print(\"sending\", type(future.result))\n",
    "            next_future = self.coro.send(future.result)\n",
    "            print('got next future', next_future)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"si\")\n",
    "            return None\n",
    "        next_future.add_done_callback(self.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopped=False\n",
    "def loop():\n",
    "    while not stopped:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>sending none to initial future <__main__.MyFuture object at 0x107284550>\n",
      "...stepping\n",
      "sending <class 'NoneType'>\n",
      "about to yield connection future\n",
      "got next future <__main__.MyFuture object at 0x107284e10>\n",
      ">>>after priming\n",
      "on connected cb ran\n",
      "sending <class 'NoneType'>\n",
      "we were connected! now back in gen\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x107284550>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 1396\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x107284588>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 1396\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x107284d30>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 4096\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x107284278>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 626\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x107284470>\n",
      "sending <class 'bytes'>\n",
      "all read\n",
      "si\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('/353/', 'xkcd.com')\n",
    "Task(fetcher.fetch())\n",
    "stopped=False\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refactoring using generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#But when the future resolves, what resumes the generator? We need a coroutine driver. Let us call it \"task\":\n",
    "#(this is our main)\n",
    "class Task:\n",
    "    def __init__(self, coro):\n",
    "        self.coro = coro\n",
    "        f = MyFuture()\n",
    "        print(\">>sending none to initial future\",f)\n",
    "        f.set_result(None)\n",
    "        print(\"...stepping\")\n",
    "        self.step(f)\n",
    "        print(\">>>after priming\")\n",
    "\n",
    "    def step(self, future):\n",
    "        try:\n",
    "            print(\"sending\", type(future.result))\n",
    "            next_future = self.coro.send(future.result)\n",
    "            print('got next future', next_future)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"si\")\n",
    "            return None\n",
    "        next_future.add_done_callback(self.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(sock):\n",
    "    f = MyFuture()\n",
    "\n",
    "    def on_readable():\n",
    "        f.set_result(sock.recv(4096))\n",
    "\n",
    "    selector.register(sock.fileno(), EVENT_READ, on_readable)\n",
    "    chunk = yield f  # Read one chunk.\n",
    "    selector.unregister(sock.fileno())\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_all(sock):\n",
    "    global stopped\n",
    "    response = []\n",
    "    # Read whole response.\n",
    "    chunk = yield from read(sock)\n",
    "    while chunk:\n",
    "        response.append(chunk)\n",
    "        chunk = yield from read(sock)\n",
    "    stopped=True\n",
    "    return b''.join(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">If you squint and make the yield from statements disappear it looks like  conventional functions doing blocking I/O. But in fact, read and read_all are coroutines. Yielding from read pauses read_all until the I/O completes. While read_all is paused, asyncio's event loop does other work and awaits other I/O events; read_all is resumed with the result of read on the next loop tick once its event is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    \n",
    "    def __init__(self, url, host):\n",
    "        self.url = url\n",
    "        self.host = host\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "\n",
    "        \n",
    "    def fetch(self):\n",
    "        global stopped\n",
    "        sock = socket.socket()\n",
    "\n",
    "        sock.setblocking(False)\n",
    "        try:\n",
    "            sock.connect((host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        f = MyFuture()\n",
    "\n",
    "        def on_connected():\n",
    "            print('on connected cb ran')\n",
    "            f.set_result(None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        selector.register(sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          on_connected)\n",
    "        print(\"about to yield connection future\")\n",
    "        yield f\n",
    "        print('connected!')\n",
    "        selector.unregister(sock.fileno())\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(self.url)\n",
    "        sock.send(request.encode('ascii'))\n",
    "        yield from read_all(sock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>sending none to initial future <__main__.MyFuture object at 0x107293a90>\n",
      "...stepping\n",
      "sending <class 'NoneType'>\n",
      "about to yield connection future\n",
      "got next future <__main__.MyFuture object at 0x107293ac8>\n",
      ">>>after priming\n",
      "on connected cb ran\n",
      "sending <class 'NoneType'>\n",
      "connected!\n",
      "got next future <__main__.MyFuture object at 0x107293f60>\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x107293630>\n",
      "sending <class 'bytes'>\n",
      "si\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('/353/', 'xkcd.com')\n",
    "Task(fetcher.fetch())\n",
    "stopped = False\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://aosabook.org/en/500L/crawler-images/yield-from.png)\n",
    "\n",
    "There is one yield left amongst the yield froms. For consistency, this can be fixed...it also lets us change implementations under the hood.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(sock):\n",
    "    f = MyFuture()\n",
    "\n",
    "    def on_readable():\n",
    "        f.set_result(sock.recv(4096))\n",
    "\n",
    "    selector.register(sock.fileno(), EVENT_READ, on_readable)\n",
    "    chunk = yield from f  # Read one chunk.\n",
    "    selector.unregister(sock.fileno())\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFuture:\n",
    "    def __init__(self):\n",
    "        self.result = None\n",
    "        self._callbacks = []\n",
    "\n",
    "    def add_done_callback(self, fn):\n",
    "        self._callbacks.append(fn)\n",
    "\n",
    "    def set_result(self, result):\n",
    "        self.result = result\n",
    "        print(\"cblist\", self._callbacks)\n",
    "        for fn in self._callbacks:\n",
    "            fn(self)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        yield self\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    \n",
    "    def __init__(self, url, host):\n",
    "        self.url = url\n",
    "        self.host = host\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "\n",
    "        \n",
    "    def fetch(self):\n",
    "        global stopped\n",
    "        sock = socket.socket()\n",
    "\n",
    "        sock.setblocking(False)\n",
    "        try:\n",
    "            sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        f = MyFuture()\n",
    "\n",
    "        def on_connected():\n",
    "            print('on connected cb ran')\n",
    "            f.set_result(None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        selector.register(sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          on_connected)\n",
    "        print(\"about to yield connection future\")\n",
    "        yield from f\n",
    "        print('connected!')\n",
    "        selector.unregister(sock.fileno())\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(self.url)\n",
    "        sock.send(request.encode('ascii'))\n",
    "        yield from read_all(sock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>sending none to initial future <__main__.MyFuture object at 0x1072b07b8>\n",
      "cblist []\n",
      "...stepping\n",
      "sending <class 'NoneType'>\n",
      "about to yield connection future\n",
      "got next future <__main__.MyFuture object at 0x1072b0ef0>\n",
      ">>>after priming\n",
      "on connected cb ran\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'NoneType'>\n",
      "connected!\n",
      "got next future <__main__.MyFuture object at 0x1072b0dd8>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x1072b0d68>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x1072b08d0>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x1072b0dd8>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x1072b0d68>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x1072b08d0>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x1072a9be0>>]\n",
      "sending <class 'bytes'>\n",
      "si\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('/353/','xkcd.com')\n",
    "Task(fetcher.fetch())\n",
    "stopped = False\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "Implement a URL fetcher using Beautiful Soup in the callback version. We will implement a similar one using coroutines on wednesday. \n",
    "\n",
    "The implimentation will extend the read_response method by parsing for URL's using `bs4` . Start by creating globals:\n",
    "```\n",
    "urls_todo = set(['/'])\n",
    "seen_urls = set(['/'])\n",
    "```\n",
    "\n",
    "then:\n",
    "\n",
    "```\n",
    "links = self.parse_links()#write this\n",
    "```\n",
    "(using self.response)\n",
    "\n",
    "Then use the set `difference` method  to add new links to `urls_todo` and recursively set up a `Fetcher` instance.\n",
    "\n",
    "Now update the `seen_urls` and `urls_todo` thus:\n",
    "```\n",
    "seen_urls.update(links)\n",
    "urls_todo.remove(self.url)\n",
    "if not urls_todo:\n",
    "    stopped = True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "\n",
    "selector = DefaultSelector()\n",
    "class Fetcher:\n",
    "    def __init__(self,  url, host):\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "        self.host = host\n",
    "        self.url = url\n",
    "        self.sock = None\n",
    "        \n",
    "    # Method on Fetcher class.\n",
    "    def fetch(self):\n",
    "        self.sock = socket.socket()\n",
    "        self.sock.setblocking(False)\n",
    "        try:\n",
    "            self.sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        # Register next callback.\n",
    "        selector.register(self.sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          self.connected)\n",
    "\n",
    "    def connected(self, key, mask):\n",
    "        print('connected!', flush=True)\n",
    "        selector.unregister(key.fd)\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(self.url, self.host)\n",
    "        self.sock.send(request.encode('ascii'))\n",
    "\n",
    "        # Register the next callback.\n",
    "        selector.register(key.fd,\n",
    "                          EVENT_READ,\n",
    "                          self.read_response)\n",
    "        \n",
    "    def read_response(self, key, mask):\n",
    "        global stopped\n",
    "        global counter\n",
    "        \n",
    "        chunk = self.sock.recv(128)  # USUALLY 4k chunk size, here small\n",
    "        if chunk:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            self.response += chunk\n",
    "        else:\n",
    "            print(\"all read\", flush=True)\n",
    "            selector.unregister(key.fd)  # Done reading. Still want to keep this\n",
    "            # remove completed url\n",
    "            urls_todo.remove(self.url)\n",
    "            \n",
    "            # create things update globals\n",
    "            links = self.parse_links()\n",
    "            \n",
    "            # filter already seend\n",
    "            # Then use the set difference method to add new links to urls_todo and recursively set up a Fetcher instance.\n",
    "            # loop through the links in to do\n",
    "            for link in links.difference(seen_urls):\n",
    "                counter += 1\n",
    "                if counter < maxit: \n",
    "                    urls_todo.add(link)\n",
    "                    # create new Fetcher and call fetch\n",
    "                    Fetcher(link, self.host).fetch()  # <- New Fetcher.\n",
    "                else: \n",
    "                    break\n",
    "\n",
    "            seen_urls.update(links)\n",
    "            # do not stopped to True until urls_to_do is empty\n",
    "            if not urls_todo:\n",
    "                stopped = True                                \n",
    "                \n",
    "    def parse_links(self):\n",
    "        # empty list of URLS\n",
    "        # look through self.response to get a list of URLs, add to the list\n",
    "        # return the list\n",
    "        links = []\n",
    "        soup = BeautifulSoup(self.response,  \"lxml\")\n",
    "        links = [link['href'] for link in soup.find_all('a', href=True)]\n",
    "        return set(links)\n",
    "            \n",
    "stopped = False\n",
    "\n",
    "def loop():\n",
    "    while not stopped:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback(event_key, event_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected!\n",
      "......................................................all read\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      ".................................all read\n",
      "..............................all read\n",
      "....................all read\n",
      "....................................................................................................................................................................................all read\n",
      "......................................................................all read\n",
      "....all read\n",
      "all read\n",
      "...all read\n",
      "all read\n"
     ]
    }
   ],
   "source": [
    "# url added here when Fetcher created.  Better name would be urls_fetching\n",
    "# set up globals\n",
    "urls_todo = set(['/'])\n",
    "# superset of urls_todo\n",
    "seen_urls = set(['/'])\n",
    "maxit = 10  \n",
    "counter = 0\n",
    "\n",
    "fetcher = Fetcher('/', 'xkcd.com')\n",
    "fetcher.fetch()\n",
    "loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not that long, basically start at some page \n",
    "# extract links from page \n",
    "# use this callback system to fetch those links \n",
    "# parse response and create new links \n",
    "# let the whole thing complete\n",
    "\n",
    "# at the end of it, will have a depth1 parser, don't want to keep going down and won\n",
    "# might want to add level argument to this class to tell you what level ought to be \n",
    "# say that level = 0, as a default, in the Fetcher, if level = 0, then let them go into it \n",
    "# class Fetcher:\n",
    "#    def __init__(self, host, url, level = 0):\n",
    "\n",
    "# don't worry about getting all the urls, just get the ones from xkcd, within one domain\n",
    "\n",
    "# There are 3 versions of the Fetcher class in the lecture notebook.  One of them (the first one) registers the \n",
    "# callbacks inside it, so the instructions mean rewrite the first Fetcher example (the callback one) using Beautiful \n",
    "# Soup to implement a URL fetcher.\n",
    "\n",
    "# See \"Programming with Callbacks\" section: \n",
    "# http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call seen_urls.difference(links) to see what links I haven't seen yet \n",
    "# add them to urls_to_do\n",
    "# TODO recursively set up a fetcher instance??? \n",
    "# want some max # of active Fetchers at any given time, then add more Fetchers if Urls_to_do\n",
    "# naive thing to do is to ...?\n",
    "\n",
    "# urls_fetching or urls_acting\n",
    "# every time add to urls_to_do, you should also construct a Fetcher and call its Fetch method, only do that if it's not \n",
    "# already in urls_to_do\n",
    "\n",
    "# seen_urls is superset of urls to do, \n",
    "# always add all the links to seen_urls. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
